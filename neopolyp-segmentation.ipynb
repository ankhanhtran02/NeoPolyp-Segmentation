{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-23T13:22:01.280198Z",
     "iopub.status.busy": "2024-11-23T13:22:01.279896Z",
     "iopub.status.idle": "2024-11-23T13:22:15.608651Z",
     "shell.execute_reply": "2024-11-23T13:22:15.607476Z",
     "shell.execute_reply.started": "2024-11-23T13:22:01.280173Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:22:18.337124Z",
     "iopub.status.busy": "2024-11-23T13:22:18.336777Z",
     "iopub.status.idle": "2024-11-23T13:22:24.228925Z",
     "shell.execute_reply": "2024-11-23T13:22:24.228034Z",
     "shell.execute_reply.started": "2024-11-23T13:22:18.337089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:22:45.129625Z",
     "iopub.status.busy": "2024-11-23T13:22:45.129245Z",
     "iopub.status.idle": "2024-11-23T13:22:45.140259Z",
     "shell.execute_reply": "2024-11-23T13:22:45.139333Z",
     "shell.execute_reply.started": "2024-11-23T13:22:45.129593Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower1 = np.array([0, 100, 20])\n",
    "        upper1 = np.array([10, 255, 255])\n",
    "\n",
    "        lower2 = np.array([160,100,20])\n",
    "        upper2 = np.array([179,255,255])\n",
    "        lower_mask = cv2.inRange(image, lower1, upper1)\n",
    "        upper_mask = cv2.inRange(image, lower2, upper2)\n",
    "        \n",
    "        red_mask = lower_mask + upper_mask;\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "    def show_image(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = plt.imread(img_path)\n",
    "        label = plt.imread(label_path)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        axs[0].imshow(image)\n",
    "        axs[0].set_title('Image')\n",
    "        axs[1].imshow(label)\n",
    "        axs[1].set_title('Label')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:22:34.661864Z",
     "iopub.status.busy": "2024-11-23T13:22:34.661425Z",
     "iopub.status.idle": "2024-11-23T13:22:34.666019Z",
     "shell.execute_reply": "2024-11-23T13:22:34.664971Z",
     "shell.execute_reply.started": "2024-11-23T13:22:34.661830Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:22:51.516546Z",
     "iopub.status.busy": "2024-11-23T13:22:51.515705Z",
     "iopub.status.idle": "2024-11-23T13:23:21.823887Z",
     "shell.execute_reply": "2024-11-23T13:23:21.822925Z",
     "shell.execute_reply.started": "2024-11-23T13:22:51.516513Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= (256,256),\n",
    "                             transform = None)\n",
    "images_data = []\n",
    "labels_data = []\n",
    "for x,y in dataset:\n",
    "    images_data.append(x)\n",
    "    labels_data.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:23:21.825711Z",
     "iopub.status.busy": "2024-11-23T13:23:21.825399Z",
     "iopub.status.idle": "2024-11-23T13:23:21.831667Z",
     "shell.execute_reply": "2024-11-23T13:23:21.830840Z",
     "shell.execute_reply.started": "2024-11-23T13:23:21.825679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(CustomImageDataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.data[index]\n",
    "        label = self.targets[index]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:23:21.832753Z",
     "iopub.status.busy": "2024-11-23T13:23:21.832502Z",
     "iopub.status.idle": "2024-11-23T13:23:24.163782Z",
     "shell.execute_reply": "2024-11-23T13:23:24.162853Z",
     "shell.execute_reply.started": "2024-11-23T13:23:21.832730Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:23:29.195099Z",
     "iopub.status.busy": "2024-11-23T13:23:29.194747Z",
     "iopub.status.idle": "2024-11-23T13:23:29.379065Z",
     "shell.execute_reply": "2024-11-23T13:23:29.378118Z",
     "shell.execute_reply.started": "2024-11-23T13:23:29.195067Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 100\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:23:32.551098Z",
     "iopub.status.busy": "2024-11-23T13:23:32.550762Z",
     "iopub.status.idle": "2024-11-23T13:23:32.560178Z",
     "shell.execute_reply": "2024-11-23T13:23:32.559295Z",
     "shell.execute_reply.started": "2024-11-23T13:23:32.551068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "train_size = 900\n",
    "val_size = 100\n",
    "train_dataset = CustomDataset(images_data[:train_size], labels_data[:train_size], transform=train_transform)\n",
    "val_dataset = CustomDataset(images_data[train_size:], labels_data[train_size:], transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:03:50.241507Z",
     "iopub.status.busy": "2024-11-23T12:03:50.241185Z",
     "iopub.status.idle": "2024-11-23T12:03:50.812099Z",
     "shell.execute_reply": "2024-11-23T12:03:50.811241Z",
     "shell.execute_reply.started": "2024-11-23T12:03:50.241482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image,label = train_dataset[0]\n",
    "\n",
    "label_array = label.permute(1, 2, 0).numpy()\n",
    "image_array = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(image_array)\n",
    "axs[0].set_title('Image')\n",
    "axs[0].axis('off')  \n",
    "\n",
    "axs[1].imshow(label_array)\n",
    "axs[1].set_title('Label')\n",
    "axs[1].axis('off')  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:03:50.813478Z",
     "iopub.status.busy": "2024-11-23T12:03:50.813203Z",
     "iopub.status.idle": "2024-11-23T12:04:01.786540Z",
     "shell.execute_reply": "2024-11-23T12:04:01.785637Z",
     "shell.execute_reply.started": "2024-11-23T12:03:50.813452Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "!wandb login # Insert your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:04:01.788154Z",
     "iopub.status.busy": "2024-11-23T12:04:01.787859Z",
     "iopub.status.idle": "2024-11-23T12:04:01.792812Z",
     "shell.execute_reply": "2024-11-23T12:04:01.791901Z",
     "shell.execute_reply.started": "2024-11-23T12:04:01.788126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "RUN_NAME = '2nd_run'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:04:01.794028Z",
     "iopub.status.busy": "2024-11-23T12:04:01.793759Z",
     "iopub.status.idle": "2024-11-23T12:04:06.379917Z",
     "shell.execute_reply": "2024-11-23T12:04:06.379078Z",
     "shell.execute_reply.started": "2024-11-23T12:04:01.793977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    project = 'NeoPolyp Segmentation',\n",
    "    config = {\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate,\n",
    "        'num_epochs': num_epochs,\n",
    "        'optimizer':'Adam',\n",
    "        'loss_fn': 'Cross Entropy'\n",
    "    },\n",
    "    name = RUN_NAME\n",
    ")\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:23:40.477720Z",
     "iopub.status.busy": "2024-11-23T13:23:40.477342Z",
     "iopub.status.idle": "2024-11-23T13:23:40.482829Z",
     "shell.execute_reply": "2024-11-23T13:23:40.481923Z",
     "shell.execute_reply.started": "2024-11-23T13:23:40.477683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T12:55:03.081625Z",
     "iopub.status.busy": "2024-11-23T12:55:03.081182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        outputs = model(images)\n",
    "    \n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            val_loss += loss_fn(outputs.float(),labels.long()).item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = f'colorization_model.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "        print('Save new model')\n",
    "    wandb.log({'Validation loss': val_loss/len(val_loader),\n",
    "               'Train loss': train_loss/len(train_loader)\n",
    "              })\n",
    "\n",
    "    label = labels[0].cpu().numpy()\n",
    "    label = mask_to_rgb(label,color_dict)\n",
    "    outputs[0] = outputs[0].softmax(dim=0)\n",
    "    output = outputs[0].cpu().numpy()\n",
    "    output = np.argmax(output, axis=0)\n",
    "    output = mask_to_rgb(output,color_dict)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axs[0].imshow(label)\n",
    "    axs[0].set_title('Label')\n",
    "    axs[1].imshow(output)\n",
    "    axs[1].set_title('Output')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:24:28.206835Z",
     "iopub.status.busy": "2024-11-23T13:24:28.206249Z",
     "iopub.status.idle": "2024-11-23T13:24:31.466018Z",
     "shell.execute_reply": "2024-11-23T13:24:31.465302Z",
     "shell.execute_reply.started": "2024-11-23T13:24:28.206802Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/kaggle/input/unetpp2/pytorch/default/1/colorization_model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:25:24.011103Z",
     "iopub.status.busy": "2024-11-23T13:25:24.010259Z",
     "iopub.status.idle": "2024-11-23T13:25:24.016741Z",
     "shell.execute_reply": "2024-11-23T13:25:24.015853Z",
     "shell.execute_reply.started": "2024-11-23T13:25:24.011056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the parent and new directory names\n",
    "parent_directory = \"/kaggle/working/\"\n",
    "new_directory = os.path.join(parent_directory, \"prediction\")\n",
    "\n",
    "# Create the parent directory (if it doesn't exist)\n",
    "if not os.path.exists(parent_directory):\n",
    "    os.makedirs(parent_directory)\n",
    "\n",
    "# Create the new directory inside the parent directory\n",
    "os.makedirs(new_directory, exist_ok=True)\n",
    "\n",
    "print(os.listdir(parent_directory))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:26:01.209346Z",
     "iopub.status.busy": "2024-11-23T13:26:01.208997Z",
     "iopub.status.idle": "2024-11-23T13:26:21.699663Z",
     "shell.execute_reply": "2024-11-23T13:26:21.698694Z",
     "shell.execute_reply.started": "2024-11-23T13:26:01.209316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainsize = 256\n",
    "model.eval()\n",
    "for i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n",
    "    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n",
    "    ori_img = cv2.imread(img_path)\n",
    "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    ori_w = ori_img.shape[0]\n",
    "    ori_h = ori_img.shape[1]\n",
    "    img = cv2.resize(ori_img, (trainsize, trainsize))\n",
    "    transformed = val_transform(image=img)\n",
    "    input_img = transformed[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n",
    "    mask = cv2.resize(output_mask, (ori_h, ori_w))\n",
    "    mask = np.argmax(mask, axis=2)\n",
    "    mask_rgb = mask_to_rgb(mask, color_dict)\n",
    "    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:35:14.170793Z",
     "iopub.status.busy": "2024-11-23T13:35:14.170060Z",
     "iopub.status.idle": "2024-11-23T13:35:15.605581Z",
     "shell.execute_reply": "2024-11-23T13:35:15.604687Z",
     "shell.execute_reply.started": "2024-11-23T13:35:14.170759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'submission.csv', index=False)\n",
    "print('Saved output.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-23T13:35:41.174488Z",
     "iopub.status.busy": "2024-11-23T13:35:41.173616Z",
     "iopub.status.idle": "2024-11-23T13:35:41.180524Z",
     "shell.execute_reply": "2024-11-23T13:35:41.179464Z",
     "shell.execute_reply.started": "2024-11-23T13:35:41.174454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Provide a download link for the saved file\n",
    "download_link = FileLink('submission.csv')\n",
    "display(download_link)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 172497,
     "modelInstanceId": 150006,
     "sourceId": 176179,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
